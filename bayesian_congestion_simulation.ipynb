{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Grid Congestion Analysis\n",
    "\n",
    "This notebook extends our grid congestion analysis using Bayesian statistical methods. While Monte Carlo simulation helps us understand the probability of congestion under different scenarios, Bayesian modeling allows us to:\n",
    "\n",
    "1. Quantify uncertainty in our estimates\n",
    "2. Infer the relative impact of different technologies (EVs vs. PVs)\n",
    "3. Make probabilistic predictions for new scenarios\n",
    "4. Incorporate prior knowledge into our analysis\n",
    "\n",
    "The Bayesian approach provides a more rigorous statistical framework for understanding the factors that contribute to grid congestion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "First, we'll import the necessary libraries and define our simulation parameters. We'll use PyMC for Bayesian modeling and ArviZ for visualization of Bayesian inference results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to imports\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "# Parameters\n",
    "N_HOUSES = 50\n",
    "HOURS = 24\n",
    "TRANSFORMER_CAPACITY = 125  # kW\n",
    "TRANSFORMER_ID = \"TR_001\"\n",
    "DATA_DIR = \"data/generated\"\n",
    "RESULTS_FILE = f\"{DATA_DIR}/monte_carlo_results.csv\"\n",
    "N_SIMULATIONS = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model Definition\n",
    "\n",
    "Here we define a Bayesian logistic regression model to predict congestion probability based on the number of EVs and PVs. The model includes:\n",
    "\n",
    "- An intercept term (alpha) representing the baseline congestion risk\n",
    "- Coefficients for EV and PV counts (beta_ev, beta_pv) representing their impact on congestion\n",
    "- A noise term (sigma) to account for unexplained variation\n",
    "\n",
    "We standardize the predictors (EV and PV counts) to improve model convergence and make the coefficients more interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bayesian_congestion_model(results_df, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Build a Bayesian model to predict congestion probability based on EV and PV counts\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with simulation results\n",
    "        n_samples: Number of samples for MCMC\n",
    "    \n",
    "    Returns:\n",
    "        Inference data object with posterior samples and standardization parameters\n",
    "    \"\"\"\n",
    "    # Extract data\n",
    "    n_ev = results_df['n_ev'].values\n",
    "    n_pv = results_df['n_pv'].values\n",
    "    congestion = results_df['congestion_probability'].values\n",
    "    \n",
    "    # Standardize predictors\n",
    "    ev_mean, ev_std = n_ev.mean(), n_ev.std()\n",
    "    pv_mean, pv_std = n_pv.mean(), n_pv.std()\n",
    "    \n",
    "    n_ev_std = (n_ev - ev_mean) / ev_std\n",
    "    n_pv_std = (n_pv - pv_mean) / pv_std\n",
    "    \n",
    "    # Define model\n",
    "    with pm.Model() as model:\n",
    "        # Priors\n",
    "        alpha = pm.Normal('alpha', mu=0, sigma=1)\n",
    "        beta_ev = pm.Normal('beta_ev', mu=0, sigma=1)\n",
    "        beta_pv = pm.Normal('beta_pv', mu=0, sigma=1)\n",
    "        sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "        \n",
    "        # Linear predictor (logit scale)\n",
    "        mu = alpha + beta_ev * n_ev_std + beta_pv * n_pv_std\n",
    "        \n",
    "        # Likelihood (Beta distribution for probabilities)\n",
    "        theta = pm.Deterministic('theta', pm.math.invlogit(mu))\n",
    "        y = pm.Beta('y', alpha=theta*sigma, beta=(1-theta)*sigma, observed=congestion)\n",
    "        \n",
    "        # Sample from posterior\n",
    "        idata = pm.sample(n_samples, return_inferencedata=True)\n",
    "    \n",
    "    return idata, ev_mean, ev_std, pv_mean, pv_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Function\n",
    "\n",
    "This function creates a contour plot showing the predicted congestion probability across different combinations of EV and PV adoption. It uses the posterior distribution from our Bayesian model to make these predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bayesian_contour(idata, results_df, ev_mean, ev_std, pv_mean, pv_std, output_dir=DATA_DIR):\n",
    "    \"\"\"Plot contour map of congestion probability from Bayesian model\"\"\"\n",
    "    # Create prediction grid for smooth surface\n",
    "    ev_range = np.linspace(0, results_df['n_ev'].max(), 100)\n",
    "    pv_range = np.linspace(0, results_df['n_pv'].max(), 100)\n",
    "    ev_grid, pv_grid = np.meshgrid(ev_range, pv_range)\n",
    "    \n",
    "    # Standardize grid values\n",
    "    ev_grid_std = (ev_grid - ev_mean) / ev_std\n",
    "    pv_grid_std = (pv_grid - pv_mean) / pv_std\n",
    "    \n",
    "    # Get posterior samples\n",
    "    posterior = idata.posterior\n",
    "    alpha = posterior['alpha'].values.flatten()\n",
    "    beta_ev = posterior['beta_ev'].values.flatten()\n",
    "    beta_pv = posterior['beta_pv'].values.flatten()\n",
    "    \n",
    "    # Compute predicted probabilities (mean of posterior)\n",
    "    logit_p = (alpha.mean() + \n",
    "              beta_ev.mean() * ev_grid_std + \n",
    "              beta_pv.mean() * pv_grid_std)\n",
    "    \n",
    "    prob = 1 / (1 + np.exp(-logit_p))\n",
    "    \n",
    "    # Create detailed contour plot with data points\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    contour = plt.contourf(ev_grid, pv_grid, prob, cmap='YlOrRd', levels=20)\n",
    "    plt.colorbar(label='Congestion Probability')\n",
    "    \n",
    "    # Add contour lines\n",
    "    contour_lines = plt.contour(ev_grid, pv_grid, prob, colors='black', alpha=0.5, \n",
    "                               levels=[0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "    plt.clabel(contour_lines, inline=True, fontsize=8)\n",
    "    \n",
    "    # Overlay actual data points\n",
    "    sc = plt.scatter(results_df['n_ev'], results_df['n_pv'], \n",
    "                    c=results_df['congestion_probability'], \n",
    "                    cmap='YlOrRd', edgecolor='black', s=50)\n",
    "    \n",
    "    plt.title('Bayesian Model: Grid Congestion Probability')\n",
    "    plt.xlabel('Number of EVs')\n",
    "    plt.ylabel('Number of Solar PV')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/bayesian_contour_detailed.png\", dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # Create simplified contour plot for presentations\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    contour = plt.contourf(ev_grid, pv_grid, prob, cmap='YlOrRd', levels=10)\n",
    "    plt.colorbar(label='Congestion Probability')\n",
    "    \n",
    "    # Add the 50% probability contour line\n",
    "    contour_50 = plt.contour(ev_grid, pv_grid, prob, colors='blue', \n",
    "                            levels=[0.5], linewidths=2)\n",
    "    plt.clabel(contour_50, inline=True, fontsize=10, fmt='%.2f')\n",
    "    \n",
    "    # Add a text annotation for the threshold\n",
    "    mid_ev = results_df['n_ev'].max() / 2\n",
    "    mid_pv = results_df['n_pv'].max() / 2\n",
    "    plt.annotate('50% Risk Threshold', \n",
    "                 xy=(mid_ev, mid_pv),\n",
    "                 xytext=(mid_ev + 2, mid_pv + 2),\n",
    "                 arrowprops=dict(facecolor='blue', shrink=0.05),\n",
    "                 fontsize=10,\n",
    "                 color='blue')\n",
    "    \n",
    "    plt.title('Grid Congestion Risk by Technology Adoption')\n",
    "    plt.xlabel('Number of EVs')\n",
    "    plt.ylabel('Number of Solar PV')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/bayesian_contour_simple.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the analysis\n",
    "\n",
    "Now we'll run the Bayesian analysis on our Monte Carlo simulation results. This includes:\n",
    "\n",
    "1. Loading the simulation results\n",
    "2. Running the Bayesian model\n",
    "3. Visualizing the posterior distributions\n",
    "4. Creating contour plots of predicted congestion probability\n",
    "5. Calculating and interpreting effect sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded results with 36 scenarios\n",
      "\n",
      "Running Bayesian model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "ename": "SamplingError",
     "evalue": "Initial evaluation of model at starting point failed!\nStarting values:\n{'alpha': array(0.43473893), 'beta_ev': array(0.15017343), 'beta_pv': array(-0.48246548), 'sigma_log__': array(-0.71643459)}\n\nLogp initial evaluation results:\n{'alpha': -1.01, 'beta_ev': -0.93, 'beta_pv': -1.04, 'sigma': -1.06, 'y': inf}\nYou can call `model.debug()` for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSamplingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2b0e6a899f72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run Bayesian model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nRunning Bayesian model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0midata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpv_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpv_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_bayesian_congestion_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-5a167b8d7fc3>\u001b[0m in \u001b[0;36mrun_bayesian_congestion_model\u001b[0;34m(results_df, n_samples)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Sample from posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0midata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inferencedata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0midata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpv_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpv_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pymc/sampling/mcmc.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, step, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, model, **kwargs)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0mip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mip\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minitial_points\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_start_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         \u001b[0m_check_start_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pymc/model.py\u001b[0m in \u001b[0;36mcheck_start_vals\u001b[0;34m(self, start)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minitial_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m                 raise SamplingError(\n\u001b[0m\u001b[1;32m   1701\u001b[0m                     \u001b[0;34m\"Initial evaluation of model at starting point failed!\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m                     \u001b[0;34mf\"Starting values:\\n{elem}\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSamplingError\u001b[0m: Initial evaluation of model at starting point failed!\nStarting values:\n{'alpha': array(0.43473893), 'beta_ev': array(0.15017343), 'beta_pv': array(-0.48246548), 'sigma_log__': array(-0.71643459)}\n\nLogp initial evaluation results:\n{'alpha': -1.01, 'beta_ev': -0.93, 'beta_pv': -1.04, 'sigma': -1.06, 'y': inf}\nYou can call `model.debug()` for more details."
     ]
    }
   ],
   "source": [
    "\n",
    "results = pd.read_csv(RESULTS_FILE)\n",
    "print(f\"Loaded results with {len(results)} scenarios\")\n",
    "\n",
    "# Run Bayesian model\n",
    "print(\"\\nRunning Bayesian model...\")\n",
    "idata, ev_mean, ev_std, pv_mean, pv_std = run_bayesian_congestion_model(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results\n",
    "\n",
    "Let's execute the main function to run our Bayesian analysis on the Monte Carlo simulation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summarize posterior\n",
    "print(\"\\nBayesian Model Summary:\")\n",
    "print(az.summary(idata))\n",
    "\n",
    "# Plot posterior distributions for specific parameters\n",
    "az.plot_posterior(idata, var_names=['alpha', 'beta_ev', 'beta_pv', 'sigma'])\n",
    "plt.suptitle(\"Posterior Distributions\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{DATA_DIR}/bayesian_posterior.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plot contour map\n",
    "plot_bayesian_contour(idata, results, ev_mean, ev_std, pv_mean, pv_std)\n",
    "\n",
    "# Calculate and print effect sizes\n",
    "posterior = idata.posterior\n",
    "beta_ev = posterior['beta_ev'].values.flatten()\n",
    "beta_pv = posterior['beta_pv'].values.flatten()\n",
    "\n",
    "print(\"\\nEffect Sizes:\")\n",
    "print(f\"EV effect (mean): {beta_ev.mean():.4f}\")\n",
    "print(f\"EV effect (95% CI): [{np.percentile(beta_ev, 2.5):.4f}, {np.percentile(beta_ev, 97.5):.4f}]\")\n",
    "print(f\"PV effect (mean): {beta_pv.mean():.4f}\")\n",
    "print(f\"PV effect (95% CI): [{np.percentile(beta_pv, 2.5):.4f}, {np.percentile(beta_pv, 97.5):.4f}]\")\n",
    "\n",
    "# Calculate probability that EV effect is greater than PV effect (in absolute terms)\n",
    "prob_ev_greater = np.mean(np.abs(beta_ev) > np.abs(beta_pv))\n",
    "print(f\"Probability |EV effect| > |PV effect|: {prob_ev_greater:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the Results\n",
    "\n",
    "The Bayesian analysis provides several key insights:\n",
    "\n",
    "1. **Effect Sizes**: The coefficients (beta_ev, beta_pv) tell us the relative impact of each technology on congestion risk. A positive coefficient increases risk, while a negative coefficient decreases it.\n",
    "\n",
    "2. **Uncertainty Quantification**: The 95% credible intervals show our uncertainty about these effects. Narrower intervals indicate more confident estimates.\n",
    "\n",
    "3. **Comparative Impact**: The probability that |EV effect| > |PV effect| tells us how confident we are that EVs have a stronger impact (positive or negative) than PVs on congestion risk.\n",
    "\n",
    "4. **Predictive Surface**: The contour plots show the predicted congestion probability across different combinations of EV and PV adoption, with the 50% threshold highlighted as a decision boundary.\n",
    "\n",
    "This analysis helps grid planners understand not just whether congestion might occur, but the relative contribution of different technologies and the uncertainty in these estimates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
